{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86aac905-e5a1-4aab-a500-15826781cd08",
   "metadata": {},
   "source": [
    "# Concurrency & multi-threadding in python\n",
    "\n",
    "- In python, only 1 thread in process can execute byte-code at a time in that process.\n",
    "- In `ThreadPoolExecutor`, each thread can execute a certain number of byte-code after which it has to release the GIL lock so that other threads can be executed.\n",
    "- Each process has it's own interpreter and memory-space and this limitation is only for threads belonging to the same process.\n",
    "- In case of processes, 2 or more processes can run on the CPU simultaneously but they can't access any shared resource in the same way.\n",
    "- We need a mutex-lock to prevent race condition and enfore consistency and concurrency between processes.\n",
    "### What is GIL?\n",
    "The **Global Interpreter Lock** (GIL) in Python, specifically in CPython (the standard implementation), is a mutex that allows only one thread to execute Python bytecode at a time within a single process. This is exactly why it is advised to use multi-threadding only when there's an I/O operation involved.\n",
    "## Using `Threads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1e8680-78ef-4cb3-a990-84b734ada34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fn_takes_time(time_in_ms: int = 2):\n",
    "    print(\"Before calling sleep function\")\n",
    "    time.sleep(time_in_ms)  # takes parameter in seconds\n",
    "    print(f\"After calling sleep for {time_in_ms * 1000} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdbf7910-06d8-4d54-b6c6-78d0b3d3c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before calling sleep function\n",
      "Main thread executing\n",
      "After calling sleep for 1000 ms\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "th = Thread(target = fn_takes_time, args = [1])\n",
    "th.start()\n",
    "print(\"Main thread executing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec51e5a-6ca5-4d76-9fa7-2abe58b1cdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before calling sleep function\n",
      "After calling sleep for 1000 ms\n",
      "Main thread executing\n"
     ]
    }
   ],
   "source": [
    "th = Thread(target = fn_takes_time, args = [1])\n",
    "th.start()\n",
    "th.join()  # joins to the main thread, acts like everything in 1 thread\n",
    "print(\"Main thread executing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed4e0e3e-873c-40ef-986b-23701a70d7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before calling sleep function\n",
      "Function running in background...\n",
      "After calling sleep for 1000 ms\n",
      "Function returned = None\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor as executor\n",
    "\n",
    "with executor(max_workers = 1) as ex:\n",
    "    future = ex.submit(fn_takes_time, 1)\n",
    "    if not future.done():\n",
    "        print(\"Function running in background...\")\n",
    "    else:\n",
    "        print(\"Function completed execution\")\n",
    "\n",
    "    # this line will not be executed until the future returns the result of computation\n",
    "    print(f\"Function returned = {future.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494c9c52-0c39-4873-8291-af1f7ffbab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_shared_resource = 0\n",
    "timings = [1, 2, 2, 1]\n",
    "\n",
    "def increment(time_in_sec: int = 1) -> int:\n",
    "    print(\"Before calling sleep function\")\n",
    "    global some_shared_resource\n",
    "    some_shared_resource += time_in_sec\n",
    "    time.sleep(time_in_sec)\n",
    "    print(f\"After calling sleep for {time_in_sec * 1000} ms\")\n",
    "    \n",
    "    return some_shared_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da79a0-5025-4ee2-8935-cf52d74d895f",
   "metadata": {},
   "source": [
    "## Using `ThreadPoolExecutor`\n",
    "- **CPU time:** The total time the CPU actively spends executing a program's instructions, excluding waiting periods.\n",
    "- **Wall time:** The total elapsed real-world time from the start to the completion of a program, including computation, I/O waits, and other delays.\n",
    "\n",
    "`ThreadPoolExecutor.map` creates a separate thread per argument, to run the function with each argument.\n",
    "## Using a single worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c932b93-39a2-4437-bba9-2fbe4b42949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before calling sleep function\n",
      "After calling sleep for 1000 ms\n",
      "Before calling sleep function\n",
      "Function returned = 1\n",
      "\n",
      "After calling sleep for 2000 ms\n",
      "Before calling sleep function\n",
      "Function returned = 3\n",
      "\n",
      "After calling sleep for 2000 ms\n",
      "Before calling sleep function\n",
      "Function returned = 5\n",
      "\n",
      "After calling sleep for 1000 ms\n",
      "Function returned = 6\n",
      "\n",
      "CPU times: user 12.9 ms, sys: 0 ns, total: 12.9 ms\n",
      "Wall time: 6.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "some_shared_resource = 0\n",
    "\n",
    "with executor(max_workers = 1) as ex:\n",
    "    future = ex.map(increment, timings)\n",
    "\n",
    "    for result in future:\n",
    "        print(f\"Function returned = {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f7936a-086b-4a10-adb0-67e36cbcdb78",
   "metadata": {},
   "source": [
    "## Using 2 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17430072-ff40-480d-a982-ae4e347a69e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before calling sleep function\n",
      "Before calling sleep function\n",
      "After calling sleep for 1000 ms\n",
      "Before calling sleep function\n",
      "Function returned = 3\n",
      "\n",
      "After calling sleep for 2000 ms\n",
      "Before calling sleep function\n",
      "Function returned = 5\n",
      "\n",
      "After calling sleep for 2000 ms\n",
      "Function returned = 6\n",
      "\n",
      "After calling sleep for 1000 ms\n",
      "Function returned = 6\n",
      "\n",
      "CPU times: user 10.6 ms, sys: 3.62 ms, total: 14.2 ms\n",
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "some_shared_resource = 0\n",
    "\n",
    "with executor(max_workers = 2) as ex:\n",
    "    future = ex.map(increment, timings)\n",
    "\n",
    "    for result in future:\n",
    "        print(f\"Function returned = {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043dae3-6576-4a8f-8c65-2ed6af6aa6b8",
   "metadata": {},
   "source": [
    "## Using 3 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56937e1-b0a1-43f5-bcd4-3330a6e6af7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before calling sleep function\n",
      "Before calling sleep function\n",
      "Before calling sleep function\n",
      "After calling sleep for 1000 ms\n",
      "Before calling sleep function\n",
      "Function returned = 5\n",
      "\n",
      "After calling sleep for 1000 ms\n",
      "After calling sleep for 2000 ms\n",
      "Function returned = 6\n",
      "\n",
      "After calling sleep for 2000 ms\n",
      "Function returned = 6\n",
      "\n",
      "Function returned = 6\n",
      "\n",
      "CPU times: user 6.63 ms, sys: 4.29 ms, total: 10.9 ms\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "some_shared_resource = 0\n",
    "\n",
    "with executor(max_workers = 3) as ex:\n",
    "    future = ex.map(increment, timings)\n",
    "\n",
    "    for result in future:\n",
    "        print(f\"Function returned = {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dbd741-5cbc-429b-a5fb-b5eb564fb75f",
   "metadata": {},
   "source": [
    "## Using 4 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85513217-f54a-4763-b3e2-391788943e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before calling sleep function\n",
      "Before calling sleep function\n",
      "Before calling sleep function\n",
      "Before calling sleep function\n",
      "After calling sleep for 1000 ms\n",
      "Function returned = 6\n",
      "\n",
      "After calling sleep for 1000 ms\n",
      "After calling sleep for 2000 ms\n",
      "Function returned = 6\n",
      "\n",
      "After calling sleep for 2000 ms\n",
      "Function returned = 6\n",
      "\n",
      "Function returned = 6\n",
      "\n",
      "CPU times: user 13.1 ms, sys: 482 µs, total: 13.5 ms\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "some_shared_resource = 0\n",
    "\n",
    "with executor(max_workers = 4) as ex:\n",
    "    future = ex.map(increment, timings)\n",
    "\n",
    "    for result in future:\n",
    "        print(f\"Function returned = {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b29bb-6774-40f6-aa45-18d07e174639",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "- Each thread is assigned to a worker which runs for till a certain number of bytecode instructions is executed (controlled by `sys.setswitchinterval()` which defaults to 5ms) after which the GIL is released.\n",
    "- A new thread then locks the GIL and starts it's execution.\n",
    "***\n",
    "## Using `ProcessPoolExecutor`\n",
    "\n",
    "**Task:** Let's create a pool of several processes all of which computes the a part or the sum of $n$ numbers and adds it to a shared `integer` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4475abf-abc5-4c11-97ee-0760d5e521fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Value, Lock\n",
    "\n",
    "\"\"\"\n",
    "'i': Signed integer (equivalent to C’s int).\n",
    "'I' Unsigned integer (equivalent to C’s unsigned int).\n",
    "'h': Signed short integer.\n",
    "'H': Unsigned short integer.\n",
    "'l': Signed long integer.\n",
    "'L': Unsigned long integer.\n",
    "\"\"\"\n",
    "\n",
    "result = Value(\"i\", 0)  # Shared integer, initialized to 0\n",
    "lock = Lock()  # Process-safe lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018c0622-bf0f-44bf-875b-3af771ec5ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(start: int, end: int, shared_integer, mutex_lock) -> int:\n",
    "    if start > end:\n",
    "        raise ValueError(\"Start cannot be greater than end\")\n",
    "\n",
    "    # assume each addition takes 1s of time\n",
    "    n = end - start + 1\n",
    "    time.sleep(n)\n",
    "\n",
    "    with mutex_lock:\n",
    "        # Protected by lock to avoid race conditions\n",
    "        shared_integer.value += sum([(start + i) for i in range(n)])\n",
    "\n",
    "    return shared_integer.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e609d9-5f2c-4add-82a0-da0009cfa16b",
   "metadata": {},
   "source": [
    "### Let's calculate the sum of fist 10 natural numbers using 3 processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa83d398-4a6a-4c08-9be6-5c2cb007ff5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 21, 55]\n",
      "CPU times: user 16.4 ms, sys: 16.4 ms, total: 32.8 ms\n",
      "Wall time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from typing import Tuple\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "partitions = [(1, 3), (4, 6), (7, 10)]\n",
    "\n",
    "def calculate_sum(args: Tuple[int]) -> int:\n",
    "    return calculate(args[0], args[1], result, lock)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers = len(partitions)) as executor:\n",
    "    results = executor.map(calculate_sum, partitions)\n",
    "    results = list(results)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00303cf8-a82b-40b5-9ac5-049e6f2945d4",
   "metadata": {},
   "source": [
    "### Using 1 process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb55b9f-7772-44dd-9154-04be2c3e0ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "CPU times: user 8.43 ms, sys: 8.79 ms, total: 17.2 ms\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = Value(\"i\", 0)  # Shared integer, initialized to 0\n",
    "lock = Lock()  # Process-safe lock\n",
    "\n",
    "with ProcessPoolExecutor(max_workers = 1) as executor:\n",
    "    future = executor.submit(calculate_sum, (1, 10))\n",
    "    print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd3129-1b60-4268-bcac-f830cdeb8a6a",
   "metadata": {},
   "source": [
    "Since the computation of the sum isn't based on the result of other threads, we can run each thread independent of one another.\n",
    "# Why Lambda Functions Fail with Shared Variables and Locks in `ProcessPoolExecutor`\n",
    "In Python's `multiprocessing` module, `ProcessPoolExecutor` relies on **pickling** (serialization via the `pickle` module) to pass functions and their arguments to worker processes. However, using shared variables (e.g., `multiprocessing.Value`) or mutex locks (e.g., `multiprocessing.Lock`) inside a lambda function or directly in the parameter list of `ProcessPoolExecutor.map` can lead to errors due to pickling limitations.\n",
    "\n",
    "## Issues with Lambda Functions\n",
    "Lambda functions (anonymous functions defined with `lambda`) cannot be pickled because they lack a stable name or module reference required by the `pickle` module. When used in `ProcessPoolExecutor.map`, such as in:\n",
    "\n",
    "```python\n",
    "results = list(executor.map(lambda x: process_range(x, counter, lock), args))\n",
    "```\n",
    "\n",
    "a `PicklingError` occurs, typically with a message like:\n",
    "\n",
    "```\n",
    "PicklingError: Can't pickle <function <lambda> at ...>: attribute lookup <lambda> on __main__ failed\n",
    "```\n",
    "\n",
    "This happens because `ProcessPoolExecutor` tries to serialize the lambda function to send it to worker processes, but lambdas are not picklable.\n",
    "\n",
    "## Issues with Shared Variables and Locks in Parameter Lists\n",
    "Shared variables (`multiprocessing.Value`) and mutex locks (`multiprocessing.Lock`) are designed to be shared through **inheritance** by creating them in the parent process and passing them to worker processes. While these objects are picklable (unlike lambdas), using them directly inside a lambda or incorrectly in the parameter list of `ProcessPoolExecutor.map` can still cause issues if the function itself is not picklable. For example:\n",
    "\n",
    "```python\n",
    "counter = Value(\"i\", 0)\n",
    "lock = Lock()\n",
    "results = list(executor.map(lambda x: some_function(x, counter, lock), args))\n",
    "```\n",
    "\n",
    "This fails with a `PicklingError` due to the lambda, not because of `counter` or `lock`. However, passing `counter` and `lock` correctly requires creating them in the parent process and including them in the argument list explicitly, as shown in a proper implementation.\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python kernel developed by Saptarshi Dey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
